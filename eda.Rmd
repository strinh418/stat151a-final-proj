---
title: "STAT 151A Final Project"
author: "Benjamin Lee, Stephanie Trinh, Zhi Long Yeo"
date: "2023-04-05"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(dbplyr)
library(caret)
library(pracma)
library(gridExtra)

knitr::opts_chunk$set(echo = TRUE)
```

# Model Question

**TODO: Questions to answer**

-   What is the research question that you plan to answer via linear modeling? What practical decisions or real-world insight could result from your project?
-   Explain whether the primary focus of your project is prediction accuracy, causal inference, or observational/exploratory.

# Data Overview

**TODO: Questions to answer**

-   Roughly, what is contained in the data? How were your data generated? What is a unit of observation? Are observations independent?
-   If you did not use one of the 3 given data sets, please provide a link to the data source.
-   Is the sample narrowly defined or is do you think modeling on this data can be generalized to a larger population?
-   What do you anticipate to be a challenge for this data/analysis?
-   Name some features or additional data that is unavailable but you think would improve modeling of your question, and discuss why.

# EDA
``` {r}
df = read.csv('combined_dataset_cleaned.csv', colClasses= c("integer", "character", "logical", "character", "numeric", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "character", "integer", "logical", "logical"))

london_df = df[df$location == "london", ]
washington_df = df[df$location == "washington_dc", ]
seoul_df = df[df$location == "seoul", ]
```

```{r, fig.width=36, fig.height=24, fig.align='center'}
library(ggpubr)

selected_hr = 18
is_weekend = 0
colors = data.frame(
  season = c('winter', 'spring', 'summer', 'fall'),
  color=c('blue', 'green', 'red', 'orange')
)

select_by_location_hour_workday = function(df, location, hour, workday) {
  output = df[(df$location == location) & (df$hr == hour) & (df$is_workday == workday), ]
  output$cnt = output$cnt / as.numeric(max(output$cnt))
  return(output)
}

plot_by_location_hour_workday = function(df, location, hour, workday) {
  restricted_df = select_by_location_hour_workday(df, location, hour, workday)
  output = ggplot(restricted_df, aes(x=temp, y=cnt, color=season)) +
    geom_point() + 
    theme(legend.position='bottom', legend.direction = 'horizontal')
  return(output)
}

london1 = select_by_location_hour_workday(df, "london", 8, TRUE)
london2 = select_by_location_hour_workday(df, "london", 12, TRUE)
london3 = select_by_location_hour_workday(df, "london", 18, TRUE)

dc1 = select_by_location_hour_workday(df, "washington_dc", 8, TRUE)
dc2 = select_by_location_hour_workday(df, "washington_dc", 12, TRUE)
dc3 = select_by_location_hour_workday(df, "washington_dc", 18, TRUE)

seoul1 = select_by_location_hour_workday(df, "seoul", 8, TRUE)
seoul2 = select_by_location_hour_workday(df, "seoul", 12, TRUE)
seoul3 = select_by_location_hour_workday(df, "seoul", 18, TRUE)

joined = rbind(london1, london2, london3,
               dc1, dc2, dc3,
               seoul1, seoul2, seoul3)
joined$hr = paste(as.character(joined$hr), rep("hr", length(joined)))

ggplot(data=joined, mapping=aes(temp, cnt, color=season)) + 
  geom_point() + 
  facet_wrap(~ location + hr) + 
  theme(text = element_text(size=40))
```

$cnt$ is the number of registered users normalized by the maximum of each location.

We see that in Seoul, during different seasons, there are different trends of count against temp. In winter we observe that the gradient of count with respect to temp is small and positive, in spring and fall, it is moderately positive and strongly negative in summer. This trend is not seen in London and much less obvious in Washington D.C. This gives us justification to use the interaction term $temp*location*season$ and all other interaction terms implied by the principle of marginality with the inclusion of this term.

We posit that this is because the annual temperature ranges in London and Washington DC is similar to that of Seoul's temperature range during Spring/Fall, because we see that the gradient of count against temp seems to be negative when temperature approaches the typical summer temperature of Seoul. However, it is difficult for us to determine a proper temperature cutoff to determine the 3 specific temperature regions, hence we think that using the season as a proxy for these different temperature categories is reasonable.

``` {r, fig.width=36, fig.height=24, fig.align='center'}
location_labels <- c("seoul"="Seoul", "london"="London", "washington_dc"="Washington D.C.")

select_by_location_hour = function(df, location, hour) {
  output = df[(df$location == location) & (df$hr == hour), ]
  output$cnt = output$cnt / as.numeric(max(output$cnt))
  output$location = location_labels[output$location]
  return(output)
}

hour_label = function(hr_vec) {
  labels = c()
  for (hr in hr_vec) {
    if (hr == 0) {
      label = "12 AM"
    } else if (hr < 12) {
      label = paste0(hr, " AM")
    } else if (hr == 12) {
      label = "12 PM"
    } else {
      label = paste0(hr-12, " PM")
    }
    labels <- rbind(labels, label)

  }
  return(labels)
}

eda2_london1 = select_by_location_hour(df, "london", 8)
eda2_london2 = select_by_location_hour(df, "london", 12)
eda2_london3 = select_by_location_hour(df, "london", 18)

eda2_dc1 = select_by_location_hour(df, "washington_dc", 8)
eda2_dc2 = select_by_location_hour(df, "washington_dc", 12)
eda2_dc3 = select_by_location_hour(df, "washington_dc", 18)

eda2_seoul1 = select_by_location_hour(df, "seoul", 8)
eda2_seoul2 = select_by_location_hour(df, "seoul", 12)
eda2_seoul3 = select_by_location_hour(df, "seoul", 18)

joined2 = rbind(eda2_london1, eda2_london2, eda2_london3,
               eda2_dc1, eda2_dc2, eda2_dc3,
               eda2_seoul1, eda2_seoul2, eda2_seoul3)
joined2$hr = hour_label(joined2$hr)

ggplot(data=joined2, mapping=aes(temp, cnt, color=is_workday)) +
  geom_point(size=5) +
  facet_wrap(~ location + factor(hr, levels=c("8 AM", "12 PM", "6 PM"))) +
  xlab("Temperature (in Celcius)") +
  ylab("Rental Bike Count") +
  ggtitle("Number of Bike Rentals For Workdays vs. Non-Workdays", subtitle = "Bike counts are normalized by dividing by the max rental count based on location.") +
  theme(plot.title = element_text(hjust = 0.5, face="bold"),
        plot.subtitle = element_text(hjust = 0.5),
        axis.title = element_text(face="bold"),
        text = element_text(size=80),
        panel.spacing.x = unit(25, "mm"))
```

```{r boxplots of count against month}
boxplots <- ggplot(df, aes(x = month, y = cnt))

boxplots <- boxplots + geom_boxplot(aes(x=month, y=cnt, group=month), fill = "#00BFC4", color = "black", alpha = 0.8, outlier.color = "#F8766D", outlier.size = 0.7) + xlab("Month") + ylab("Count") + ggtitle("Boxplots of Count against Month by Location") + facet_wrap(~location, scales = "free") + scale_x_continuous(breaks=1:12)

boxplots_log <- ggplot(df, aes(x = month, y = log(cnt)))

boxplots_log <- boxplots_log + geom_boxplot(aes(x=month, y=log(cnt), group=month), fill = "#00BFC4", color = "black", alpha = 0.8, outlier.color = "#F8766D", outlier.size = 0.7) + xlab("Month") + ylab("log(Count)") + ggtitle("Boxplots of log(Count) against Month by Location") + facet_wrap(~location, scales = "free") + scale_x_continuous(breaks=1:12)
boxplots

grid.arrange(boxplots, boxplots_log, nrow=2)
```
From the top row of boxplots we observe that the average count and, in particular, variance of bike users count differs across the months. The non-uniform variance violates the canonical assumption of homoscedasticity. Furthermore, we also observe that the distribution of count in each month does not appear to be normal, as evident from the presence of numerous outliers at high values of count. In the second row, we make an attempt to normalize the data using a log-transformation in an attempt to pull in high values of count, but our resulting boxplots still show that the distribution is not normal.

These observations motivate treating the data as count data and working from a Poisson GLM framework. A Poisson framework would, in particular, address the non-uniform variance of our data. We observe that variance of count in each month increases as mean increases, which is characteristic of Poisson processes.
